% Evaluation Chapter

This section covers the evaluation done on the old Cluster Web and the new CluWeb. The aim of the evaluation is to gain knowledge about the users'opinions on Cluster Web and CluWeb and how they meet the needs of the users.

Something human computer interaction \cite{4839639}

The evaluation was done in two phases: at first, focusing only on how, why and when operations engineers and spacecraft controllers use the old Cluster Web and what are its strengths and shortcomings. The results can then help in understanding what is required from the new CluWeb to fullfill the users' needs and on what areas in particular should be a focus for improving the user experience.

In the second phase of the evaluation, an evaluation of CluWeb was performed to find out how it improved in terms of user experience. CluWeb wasn't functionally yet on par with the old Culster Web at this point of development as it was missing the pass planning functionality entirely, so the evaluation focused on two aspects which could be compared: monitoring and data visualization.

\section{Definitions}\label{definitions_section}

There are many different established methods for evaluating software usability and user experience. At first it is important to define what exactly these terms mean in scientific consensus so that there is no misunderstanding.

The definitions of usability and user experience in the context of software evaluation aren't self-evident, and they can be interpreted in many different ways. However, these terms do have official ISO standards defining them. Bevan et al.talk about the importance of using these standards so that the criteria against which software is evaluated stays consistent. \cite{bevanstandard}

In  ISO FDIS 9241-210, usability is defined as "Extent to which  a system, product or service can be used by specified users to achieve specified goals with effectiveness, efficiency and satisfaction in a specified context of use." Therefore, usability seems to have its main focus on the pragmatic goal of achieving some task in a efficient way while using the system, however it also includes the concept of satisfaction.

User experience on the other hand is defined as "A person's perceptions and responses that result from the use and/or anticipated use of a product, system or service." It would appear that user experience is more about deriving pleasure from using a system even if it is not for entertainment purposes. Also worth noting is that this also covers anticipated use, before the user has even seen the system, and how their expectations may compare to reality.

There are many ways to interpret how these terms relate to each other. If the concept of "satisfaction" in the definition of usability is considered to cover "a person's perceptions and responses" in the definition of user experience, then usability can be seen as a umbrella term that covers both the actual measurable work efficiency and personal feelings that stem from using the system.

Bevan notes that in industry it is often user experience that is used as an umbrella term that includes the work efficiency component of usability, while in research community user experience is seen as the subjective perception that user gets from using a system.

In the end there are three different interpretations of user experience according to Bevan: \begin{itemize}
\item An  elaboration  of  the  satisfaction  component  of usability
\item Distinct  from  usability,  which  has  a  historical emphasis on user performance
\item An  umbrella  term  for  all  the  userâ€™s  perceptions  and responses,  whether  measured  subjectively  or objectively
\end{itemize}
\cite{bevan2009difference}

Petrie and Bevan further open up the meanings of these terms and their components and how they're used in research community. Usability can be contain concepts like learnability, flexibility, memorability, safety and accessibility in addition to efficiency, because all these contribute to achieving some end goal through the use of the system. What exactly is considered usability is dependent to the system in question. 

According to Petrie and Bevan, users may want more from their interaction with the system than just to complete a task efficiently, and this is where user experience is an important thing to consider. Information technology has become an ubiquitous part of everyday life and is no longer just a means to an end to people.
\cite{bevanevaluation}

\cite{bevan2009difference, bevaniso, bevanevaluation, bevanstandard}

Tullis and Albert consider user experience to be a broad term that covers the user's entire interaction with the system, including their thoughts, feelings and perceptions. Their view of user experience metrics is that they reveal information about the effectiveness, efficiency and satisfaction that's a result of the interaction between the user and the system. \cite{albert2013measuring}

Hassenzahl et al. look at usability and user experience from different points of view and argue that while these terms practically cover the same things, they have slightly different focuses. Usability is more concerned with practical task completion and objectively measurable metrics, while user experience tries to balance the practical and hedonic sides of information system usage and also considers how the user feels after using the system.
\cite{hassenzahl2006user}

In Rubin's and Chisnell's definition, with an usable system "the user can do what he or she wants to do the way he or she expects to be able to do it, without hindrance, hesitation, or questions". An usable system should be "useful, efficient, effective, satisfying, learnable, and accessible". \cite{rubin2008handbook} This way of defining usability is similar to others and also covers the concept of user satisfaction. An user is more likely to use a system that generates positive feelings.

In all different definitions, usability seems to cover the basic idea that an user should be able to complete a task using the system efficiently. What is less clear is whether user experience is a part of usability or vice versa, or whether they are two separate concepts. There is support for many different interpretations.

For consistency's sake and  to not use words interchargeably in this thesis, "user experience" is going to be used as an all-encompassing term that covers every aspect of the user's interaction with the system, from their ability to learn how to use the system and complete tasks with it to what kind of feelings stem from the usage of the system. Both pragmatic and hedonic goals of information system usage should be considered, and user experience seems to be a better word for this than just usability.

\section{Methods}
In this section the methods of evaluation will be detailed. This includes what metrics are going to be collected and how. An overview of related literature is done to make sure that the evaluation is done following generally accepted standards in the industry and scientific community. Also, what is considered important in the context of Cluster Web and CluWeb is considered when designing the evaluation plan.

Because data visualization and monitoring is the part of CluWeb that is going to be evaluated, this puts less focus on clear-cut task completion. Pass planning would for example be a well-defined task that is very well suited for purely pragmatic usability evaluation, but it is absent from the current iteration of CluWeb. Inspecting a data visualization is by nature a more exploratory task for the user.

A schedule monitoring screen is continuously presenting information in the flight control room. This allows the spacecraft controllers to get an overview of the operations schedule at a glance. This screen is ubiquitously present and doesn't require direct interaction from the user. From this perspective it would make sense to evaluate what is the perceived usefulness of this screen.

The concept of usability and user experience should be split into different subcategories to form questions that should be answered through the evaluation. If we combine what was covered in section \ref{definitions_section}, at least the following categories can be found:

\textbf{Usefulness} is a measure of whether the system is actually needed. The task the system is designed for should be something that people need to or want to do, and the system should be helpful in completing that task. As Cluster Web has been in active use for many years, there is no question about its usefulness within its userbase, but this should still be evaluated to better find out what it is used for and how useful people find it for different purposes. Also for the new CluWeb it is very important to evaluate usefulness.

\textbf{Efficiency} is a measure of how good are the results of using the system relative to the resources it needs. In Cluster Web's context this could for example mean the amount of time and effort required to complete a task, which is possible to evaluate as long as the task is well defined and has a starting and an ending time.

\textbf{Effectiveness} is defined as how well the users can complete tasks using the system. The system should act reliably in a way that the user expects it to in order to be properly usable. Otherwise, the user could make errors and not complete the tasks properly. Error rate is an usual way of measuring this. For Cluster Web's evaluation, a set of test tasks could be defined with their intended outcomes, and whether or not the users could reach the right outcome would be tested.

\textbf{Learnability} means how quickly and how well the users are able to learn the system so that they can use it effectively. If the system is hard to learn, this will lead to problems in effectiveness. Too long learning period is not efficient either. Because Cluster Web's current users have been using it for many years, this cannot be evaluated very well with them, but the new CluWeb can be, especially its new features. Also people from outside of the Cluster II flight control team could be used in evaluation.

\textbf{Satisfaction} is a qualitative measure that covers the user's feelings about using the system. While many other things can be measured as quantitative numbers, it is useful to directly ask the users about their opinions and preferences. At very least, the user shouldn't feel negative emotions like frustration or confusion while and after using the system. Optimally the system would evoke some positive reaction that could encourage the user to interact with the system more. A questionnaire at the end and possibly during the evaluation would be a way of getting data about this. It could also be possible to observe nonverbal cues like facial expressions.

\textbf{Accessibility} often deals with how well the system can be used by people with disabilities, for example poor eyesight or coordination. To some extent this could be taken into account when testing Cluster Web like the visibility of small icons, but finding test subjects could be relatively hard.

\textbf{Memorability} is  a subset of learnability; how well and how quickly the user can continue using the system after being away from it for some time. Evaluating this may not be possible with the very limited timeframe that is available.

\textbf{Safety} covers the aspects of the system protecting the user from dangerous situations and undesirable conditions. This doesn't apply very much to Cluster Web, as even though it is used extensively, it doesn't play a critical part in spacecraft operations. Maybe information security could be assessed in some way as a part of safety.

\cite{rubin2008handbook, bevanevaluation, albert2013measuring}

\cite{bevanevaluation}

\cite{albert2013measuring}


%\cite{hollingsed2007usability}
%\cite{vermeeren2010user}

\section{Results}