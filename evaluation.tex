% Evaluation Chapter

This section covers the evaluation done on the old Cluster Web and the new CluWeb. The aim of the evaluation is to justify the need for a re-engineered Cluster Web and to gain qualitative and quantitative data about how the user experience was improved between the different versions.

Something human computer interaction \cite{4839639}

The evaluation was done in two phases: at first, focusing only on how, why and when operations engineers and spacecraft controllers use the old Cluster Web and what are its strengths and shortcomings. The results can then help in understanding what is required from the new CluWeb to fullfill the users' needs and on what areas in particular should be a focus for improving the user experience.

In the second phase of the evaluation, a comparative evaluation between Cluster Web and CluWeb was performed to find out how it improved in terms of user experience. CluWeb wasn't functionally yet on par with the old Culster Web at this point of development as it was missing the pass planning functionality entirely, so the evaluation focused on two aspects which could be compared: monitoring and data visualization.

\section{Definitions}

There are many different established methods for evaluating software usability and user experience. At first it is important to define what exactly these terms mean so that there is no misunderstanding.

The definitions of usability and user experience in the context of software evaluation aren't self-evident, and they can be interpreted in many different ways. However, these terms do have official ISO standards defining them. Bevan et al.talk about the importance of using these standards so that the criteria against which software is evaluated stays consistent.

In  ISO FDIS 9241-210 the definitions are as follows:


Bevan et al. say that these ISO definitions are not enough by themselves but provide a good baseline on top of which evaluation criteria can be built. New and revised standards published in 2016/2017 also add further elaboration.

\cite{bevan2009difference, bevaniso, bevanevaluation, bevanstandard}

Tullis et al define user experience as ...\cite{albert2013measuring}


\cite{nielsen1995usability, hollingsed2007usability, holzinger2005usability, rubin2008handbook, dumas1999practical, vermeeren2010user, bevan2009difference, vaananen2008towards, laugwitz2008construction, obrist2009user, battleson2001usability, van2003retrospective, hassenzahl2010needs, albert2013measuring}

\section{Results}