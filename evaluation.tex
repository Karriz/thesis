% Evaluation Chapter

This section covers the usability evaluation done on the old Cluster Web and the new CluWeb. The aim of the evaluation is to justify the need for a re-engineered Cluster Web and to gain qualitative and quantitative data about how the user experience was improved between the different versions.

Something about human-computer interaction \cite{4839639}

The evaluation was done in two phases: at first, focusing only on how, why and when operations engineers and spacecraft controllers use the old Cluster Web and what are its strengths and shortcomings. The results can then help in understanding what is required from the new CluWeb to fullfill the users' needs and on what areas in particular should be a focus for improving the user experience.

In the second phase of the evaluation, a comparative evaluation between Cluster Web and CluWeb was performed to find out how it improved in terms of usability. CluWeb wasn't functionally yet on par with the old Culster Web at this point of development as it was missing the pass planning functionality entirely, so the evaluation focused on two aspects which could be compared: monitoring and data visualization.

\section{Methods}

There are many different established methods for software usability inspection, usability testing and user experience evaluation. 

\cite{nielsen1995usability, hollingsed2007usability, holzinger2005usability, rubin2008handbook, dumas1999practical, vermeeren2010user, bevan2009difference, vaananen2008towards, laugwitz2008construction, obrist2009user, battleson2001usability, van2003retrospective}

\section{Results}